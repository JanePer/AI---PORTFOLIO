{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task4(Pro)_Обработка текстов с помощью нейросетей.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmOPeobq+EBJoieW1ZltQn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanePer/AI---PORTFOLIO/blob/main/Task4(Pro)_%D0%9E%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2_%D1%81_%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D1%81%D0%B5%D1%82%D0%B5%D0%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCOxjE-VNQTh"
      },
      "source": [
        "# **Pro**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JT8kprOgAt1"
      },
      "source": [
        "#Классификация текстов писателей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbZcR-LFPDoP"
      },
      "source": [
        "**1. Импорт библиотек.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAa_UnRidTdl",
        "outputId": "7a95a6e7-64a3-48c6-fce0-395deb26da97"
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Embedding, SpatialDropout1D, Flatten\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cG_32Vcu7aD"
      },
      "source": [
        "**2. Загрузка базы текстов.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42DhdHHJgYM7"
      },
      "source": [
        "!rm -R '/content/texts' #remove texts directory\n",
        "!unzip -q '/content/drive/MyDrive/Colab Notebooks/Тексты писателей.zip' -d '/content/texts' #unzip to created `texts` directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhv-zMjOtAsL"
      },
      "source": [
        "def readtext(file_name): #read all text in 1 raw\n",
        "  file=open(file_name, 'r')\n",
        "  text=file.read()\n",
        "  text=text.replace(\"\\n\",\" \")\n",
        "  return text\n",
        "\n",
        "authors = [\"О. Генри\", \"Стругацкие\", \"Булгаков\", \"Саймак\", \"Фрай\", \"Брэдберри\"] #list of unique authors\n",
        "authors_qty=len(authors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRd0LS3-zN5T",
        "outputId": "51b0fe78-f6a8-451e-dded-5c473ff5fbc7"
      },
      "source": [
        "train_text=[]\n",
        "test_text=[]\n",
        "\n",
        "for i in authors:\n",
        "  for t in os.listdir('/content/texts/Тексты писателей'):\n",
        "    if i in t:\n",
        "      if \"Обучающая\" in t:\n",
        "        train_text.append(readtext('/content/texts/Тексты писателей/'+t))\n",
        "      else:\n",
        "        test_text.append(readtext('/content/texts/Тексты писателей/'+t))\n",
        "print(len(train_text))\n",
        "print(len(train_text[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "1049517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxcKwnUkM59W"
      },
      "source": [
        "**3. Нормирование и преобразование данных.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVF04mzK4rK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ac1fe6-9a94-4394-ebff-2f2cef03353b"
      },
      "source": [
        "max_words_qty=20000\n",
        "toks=Tokenizer(num_words=max_words_qty, filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=\" \",\n",
        "                 oov_token='unknown', char_level=False) #create tokenizer model based on words frequency\n",
        "toks.fit_on_texts(train_text) #apply tokens to train texts\n",
        "freq_items=list(toks.word_index.items()) #extracting words with their indexes\n",
        "print(len(freq_items))\n",
        "freq_items[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "133070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('unknown', 1),\n",
              " ('и', 2),\n",
              " ('в', 3),\n",
              " ('не', 4),\n",
              " ('я', 5),\n",
              " ('что', 6),\n",
              " ('на', 7),\n",
              " ('с', 8),\n",
              " ('он', 9),\n",
              " ('а', 10)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGpGWh-TZkIp",
        "outputId": "6084f2b1-4dae-4822-9edf-f428eb1a8cea"
      },
      "source": [
        "train_word_indexes=toks.texts_to_sequences(train_text) #convert train texts into indexes\n",
        "test_word_indexes=toks.texts_to_sequences(test_text) #convert test texts into indexes\n",
        "print(train_text[2][:100])\n",
        "print(train_word_indexes[2][:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿Белая гвардия   Посвящается[1]  Любови Евгеньевне Белозерской[2]  Пошел мелкий снег и вдруг повалил\n",
            "[2939, 5529, 1, 1508, 1, 1, 16735, 1515, 353, 8296, 1267, 2, 121, 15326, 1, 1, 675, 12013, 10580, 17342]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxVTxWLaZ67y"
      },
      "source": [
        "**4. Статистика по данным.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFc9T1XaZ70L",
        "outputId": "76c9745e-f28a-4512-a927-0329023ee7c7"
      },
      "source": [
        "symbols_train_text=0\n",
        "words_train_text=0\n",
        "print(\"Train texts statistic:\")\n",
        "for i in range(authors_qty):\n",
        "  print(authors[i],\" \"*(10-len(authors[i])), len(train_text[i]), \"symbols, \", len(train_word_indexes[i]), \"words\")\n",
        "  symbols_train_text+=len(train_text[i]) #sum overall qty of symbols within all authors train texts\n",
        "  words_train_text+=len(train_word_indexes[i]) #sum overall qty of words within all authors test texts                  \n",
        "\n",
        "print('-------')\n",
        "print(\"Overall symbols: \", symbols_train_text, \" Overall words: \", words_train_text,) \n",
        "print('\\n')\n",
        "\n",
        "symbols_test_text=0\n",
        "words_test_text=0\n",
        "print(\"Test texts statistic:\")\n",
        "for i in range(authors_qty):\n",
        "  print(authors[i],\" \"*(10-len(authors[i])), len(test_text[i]), \"symbols, \", len(test_word_indexes[i]), \"words\")\n",
        "  symbols_test_text+=len(test_text[i]) #sum overall qty of symbols within all authors train texts\n",
        "  words_test_text+=len(test_word_indexes[i]) #sum overall qty of words within all authors test texts                  \n",
        "\n",
        "print('-------')\n",
        "print(\"Overall symbols: \", symbols_test_text, \" Overall words: \", words_test_text,) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train texts statistic:\n",
            "О. Генри    1049517 symbols,  160607 words\n",
            "Стругацкие  2042469 symbols,  313012 words\n",
            "Булгаков    1765648 symbols,  261465 words\n",
            "Саймак      1609507 symbols,  251502 words\n",
            "Фрай        3700010 symbols,  568533 words\n",
            "Брэдберри   1386454 symbols,  214454 words\n",
            "-------\n",
            "Overall symbols:  11553605  Overall words:  1769573\n",
            "\n",
            "\n",
            "Test texts statistic:\n",
            "О. Генри    349662 symbols,  53238 words\n",
            "Стругацкие  704846 symbols,  108621 words\n",
            "Булгаков    875042 symbols,  132730 words\n",
            "Саймак      318811 symbols,  50360 words\n",
            "Фрай        1278191 symbols,  196731 words\n",
            "Брэдберри   868673 symbols,  132524 words\n",
            "-------\n",
            "Overall symbols:  4395225  Overall words:  674204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrKb399EapAD"
      },
      "source": [
        "**5. Создание обучающей и проверочной выборки.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xbwtuh1Wxkn"
      },
      "source": [
        "def getSetIndexes(wordIndexes, xLen, step): #cut separate author's text into xLen samples\n",
        "  x_sample=[]\n",
        "  wordslen=len(wordIndexes)\n",
        "  index=0\n",
        "  while (index+xLen)<=wordslen:\n",
        "    x_sample.append(wordIndexes[index:index+xLen])\n",
        "    index+=step\n",
        "  return x_sample\n",
        "\n",
        "def getAllSetsIndexes(wordIndexes, xLen, step): #create X set cut into defined length of samples and Y set with correspond author within all authors\n",
        "  classes=len(wordIndexes) #6 authors\n",
        "  class_x_sample=[]\n",
        "  for w in wordIndexes: #take each list of 6 lists\n",
        "    class_x_sample.append(getSetIndexes(w, xLen, step)) #cut each text list into samples and append to summary list of lists\n",
        "\n",
        "  X_sam=[]\n",
        "  Y_sam=[]\n",
        "  for c in range(classes): #within 6 authors\n",
        "    cx=class_x_sample[c] #all cut samples of each author's list\n",
        "    for x in range(len(cx)): #within qty of all samples of each author\n",
        "      X_sam.append(cx[x]) #append all cut samples to final list\n",
        "      Y_sam.append(utils.to_categorical(c, classes)) #append all correspond author's vectors to final list\n",
        "\n",
        "  X_sam=np.array(X_sam)\n",
        "  Y_sam=np.array(Y_sam)\n",
        "  return (X_sam, Y_sam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9OnCUYbW1MF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab218330-aaaf-4138-edbc-b94e91c75d62"
      },
      "source": [
        "xLen=6300\n",
        "step=70\n",
        "x_train1, y_train1=getAllSetsIndexes(train_word_indexes, xLen, step)\n",
        "x_test, y_test=getAllSetsIndexes(test_word_indexes, xLen, step)\n",
        "print(x_train1.shape)\n",
        "print(y_train1.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24742, 6300)\n",
            "(24742, 6)\n",
            "(9095, 6300)\n",
            "(9095, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMEhp6CTg-zO",
        "outputId": "f6eb5fe7-00ee-4326-f692-45ad38fb0a55"
      },
      "source": [
        "x_train, x_val, y_train, y_val=train_test_split(x_train1, y_train1, test_size=0.2, shuffle=True)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19793, 6300)\n",
            "(19793, 6)\n",
            "(4949, 6300)\n",
            "(4949, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQLy9Vp9bVdJ",
        "outputId": "2cae9f58-ad84-4963-9498-f09c5cf7f8ae"
      },
      "source": [
        "x_train01=toks.sequences_to_matrix(x_train.tolist()) #convert indexes into bag of words vectors\n",
        "x_val01=toks.sequences_to_matrix(x_val.tolist())\n",
        "x_test01=toks.sequences_to_matrix(x_test.tolist())\n",
        "print(x_train01.shape)\n",
        "print(x_train01[0][:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19793, 20000)\n",
            "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kit_yGDJbm93"
      },
      "source": [
        "**6. Создание и обучение сети.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro9HPYpgEAxM",
        "outputId": "de467e16-43ca-4935-9e78-10f33339c48d"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(400, input_dim=max_words_qty, activation='sigmoid'))\n",
        "model.add(Dense(200, activation='sigmoid'))\n",
        "model.add(Dense(200, activation='sigmoid'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 400)               8000400   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 200)               80200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 1206      \n",
            "=================================================================\n",
            "Total params: 8,122,006\n",
            "Trainable params: 8,122,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jul62ZbuGyzM",
        "outputId": "ed54d61f-83b0-4ff9-9b03-cdcca9cda5d6"
      },
      "source": [
        "history=model.fit(x_train01, y_train, epochs=10, batch_size=128, validation_data=(x_val01, y_val), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "155/155 [==============================] - 5s 15ms/step - loss: 0.2211 - accuracy: 0.9483 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.4722e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 8.6734e-04 - accuracy: 1.0000 - val_loss: 5.1617e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 6.3295e-04 - accuracy: 1.0000 - val_loss: 3.7821e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 4.7864e-04 - accuracy: 1.0000 - val_loss: 2.8920e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 3.7468e-04 - accuracy: 1.0000 - val_loss: 2.2802e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 3.0423e-04 - accuracy: 1.0000 - val_loss: 1.8412e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 2.4992e-04 - accuracy: 1.0000 - val_loss: 1.5139e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q531BHA7b0e6"
      },
      "source": [
        "**7. Распознавание проверочной выборки**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWnQolDQ3I3p",
        "outputId": "ec9a4dd3-f110-41b0-ae55-0a852e9fcbe5"
      },
      "source": [
        "model.evaluate(x_test01,y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "285/285 [==============================] - 1s 3ms/step - loss: 0.0743 - accuracy: 0.9763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07427144050598145, 0.9762507081031799]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAsidTxG9fNY"
      },
      "source": [
        "Up to 98% correct answers for testing sample, not enough RAM to display accuracy by authors separately."
      ]
    }
  ]
}